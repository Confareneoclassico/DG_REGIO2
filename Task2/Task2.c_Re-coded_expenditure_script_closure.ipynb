{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2.c - Update expenditure figures from commission payments as per the previous script\n",
    "\n",
    "We here apply the script implemented in the previous tender contract to estimate expenditures also for the programming period 2014-2020.\n",
    "\n",
    "We start off from importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sobol_seq\n",
    "import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Database_Final_UPD_2020_corr.xlsx')\n",
    "df_1420 = pd.read_excel('2019-07-18_2014-2020_regionalised.xlsx')\n",
    "df_1420['ProgrammingPeriod']='2014-2020'\n",
    "df_1420 = df_1420.fillna(method='ffill')\n",
    "df_1420 = df_1420.rename(columns={'MS':'Country','NUTS1':'NUTS1Code','NUTS2':'NUTS2Code','CF':'CF_TOTAL','ERDF':'ERDF_TOTAL'})\n",
    "df_old = pd.read_csv('Old_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quasi-random numbers are then generated for our Monte Carlo simulations. The expenditure algorithm is not run only once, rather multiple times to obtain plausible estimates of the expenditure ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasiRandom_df = pd.DataFrame(sobol_seq.i4_sobol_generate(6,1000))\n",
    "DistributionFiMax = 0.8+quasiRandom_df[0]*0.2\n",
    "DistributionFiMin = 0.2+quasiRandom_df[1]*0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes are re-arranged for our convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = df[['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year','CF_TOTAL','EAGGF','ERDF_TOTAL','ESF']].copy()\n",
    "df2 = dfb.melt(id_vars=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year'],var_name='FundingScheme')\n",
    "df3 = df2.pivot_table(index=['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code'],columns='Year', values='value')\n",
    "df4 = df3.dropna(how='all').fillna(0)\n",
    "\n",
    "df_14b = df_1420.melt(id_vars=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year'],var_name='FundingScheme')\n",
    "df_14c = df_14b.pivot_table(index=['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code'],columns='Year',\n",
    "                            values='value')\n",
    "df_14d = pd.concat([df3,df_14c])\n",
    "df4 = df_14d.dropna(how='all').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anticipated payments, i.e. remitted before the commencing of the programming period, are excluded from the assessment. For instance, a payment remitted in the year 2006 in the context of the programming period 2007-2013 is attributed to an expenditure incurred in the same year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = []\n",
    "\n",
    "diff = int(np.sort(np.array(list(set(df.ProgrammingPeriod))))[0][5:])+6-\\\n",
    "int(np.sort(np.array(list(set(df.ProgrammingPeriod))))[0][:4])\n",
    "\n",
    "d_Var = pd.Series([k/diff for k in range(1,diff+1)],[y for y in \\\n",
    "range(int(np.sort(np.array(list(set(df.ProgrammingPeriod))))[0][:4]),\n",
    "int(np.sort(np.array(list(set(df.ProgrammingPeriod))))[0][5:])+6)])\n",
    "\n",
    "dummy.append(d_Var)\n",
    "\n",
    "for pp in np.sort(np.array(list(set(df.ProgrammingPeriod))))[1:-1]:\n",
    "    diff = int(pp[5:])+4-int(pp[:4])\n",
    "    \n",
    "    d_Var = pd.Series([k/diff for k in range(1,diff+1)],[y for y in range(int(pp[:4]),int(pp[5:])+4)])\n",
    "    \n",
    "    dummy.append(d_Var)\n",
    "    \n",
    "for pp in np.sort(np.array(list(set(df.ProgrammingPeriod))))[-1:]:\n",
    "    diff = int(pp[5:])+3-int(pp[:4])\n",
    "    \n",
    "    d_Var = pd.Series([k/diff for k in range(1,diff+1)],[y for y in range(int(pp[:4]),int(pp[5:])+3)])\n",
    "    \n",
    "    dummy.append(d_Var)\n",
    "    \n",
    "dummy.append(pd.Series([r/(2019-2014) for r in range(1,1+2019-2014)], [y for y in range(2014,2019)], dtype='float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative figures are then normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "\n",
    "Norm_df6 = ((df5.cumsum(axis=1).T/df5.cumsum(axis=1).max(axis=1).values).T).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm_df6.loc[pd.IndexSlice['2014-2020',:,:,:],'$\\delta$']= (Norm_df6.loc['2014-2020',dummy[-1].index]-\\\n",
    "                                                            dummy[-1].T).cumsum(axis=1).iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two outcome variables are the defined for our assessment: a) $\\delta$ which represents the difference in the cumulative areas of the payments against a dummy region; and b) $\\mu$ which is a normalised rank of the European regions for a given funding scheme under a given programming period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = list(set(df.ProgrammingPeriod))\n",
    "lp.append('2014-2020')\n",
    "\n",
    "for ip, pp in enumerate(np.sort(np.array(lp))):\n",
    "    Norm_df6.loc[pd.IndexSlice[pp,:,:,:],'$\\delta$'] = (Norm_df6.loc[pd.IndexSlice[pp,:,:,:],dummy[ip].index]-\\\n",
    "                                                        dummy[ip].T).cumsum(axis=1).iloc[:,-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = Norm_df6.groupby(['ProgrammingPeriod','FundingScheme'])\n",
    "ld = []\n",
    "for idx, df7b in df7:\n",
    "    df8 = df7b.copy()\n",
    "    df8['$\\mu$']=(df8['$\\delta$'].max()-df8['$\\delta$'])/(df8['$\\delta$'].max()-df8['$\\delta$'].min())\n",
    "    ld.append(df8)\n",
    "Norm_df7 = pd.concat(ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further modelling parameter is then defined: the trigger for the number of years the residual expenditure gets spread onto on the last eligible year of the programming period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7c = Norm_df7.groupby(['ProgrammingPeriod'])\n",
    "ld1 = []\n",
    "co = -1\n",
    "for idx, df7d in df7c:\n",
    "    co+=1\n",
    "    for iq,qr in enumerate(quasiRandom_df[2]):\n",
    "        df8b = df7d.copy()\n",
    "        df8b[0]=(qr*(df7d['$\\mu$']*(len(dummy[co])-1)).astype(int)).astype(int)+1\n",
    "        for il in range(1,len(dummy[co])):\n",
    "            df8b[il]=df8b[0]-il\n",
    "        df8b[df8b<1]=1\n",
    "        cd = [il0 for il0 in range(len(dummy[co]))]\n",
    "        df8b['value']=iq\n",
    "        cd.append('value')\n",
    "        df8b = df8b[cd]\n",
    "        ld1.append(df8b)\n",
    "years = pd.concat(ld1)\n",
    "years.set_index('value', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the yearly residues a payment may get attributed to. After having defined which share of the payment correspond to an expenditure incurred on the same year, we attribute the residual backwards to expenditure incurred in the previous years as per the figures assessed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A(n):\n",
    "    return [(2**j)/(2**n-1) for j in reversed(range(n))]\n",
    "\n",
    "B9 = []\n",
    "for k in reversed(range(2,11)):\n",
    "    B9.append(pd.DataFrame([A(y) for y in range(1,k)],index=[y for y in range(1,k)],\n",
    "                           columns=[y for y in range(1,k)]).fillna(0).sort_values(by=1,ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Payments = df5.loc[Norm_df6.index].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expenditure figures can then be assessed in a Monte Carlo simulation (repeated 1,000 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg  = df5.loc[Norm_df6.index].groupby('ProgrammingPeriod')\n",
    "co = -1\n",
    "\n",
    "Expend = []\n",
    "for r in range(len(quasiRandom_df)):\n",
    "    co = -1\n",
    "    Expe = []\n",
    "    for ie, Eg in eg:\n",
    "        co += 1\n",
    "        Exp = Eg.copy()\n",
    "        if ie == '1989-1993':\n",
    "            y = [yr for yr in range(int(ie[5:])+5,df5.columns.max())]\n",
    "\n",
    "            Exp[int(ie[5:])+5]=Eg[y].agg('sum',axis=1)\n",
    "            \n",
    "            Exp.loc[:,y[1:]] = 0\n",
    "            \n",
    "            Aggregate = Exp[int(ie[5:])+5]*(1-(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r])))\n",
    "            \n",
    "            Exp[int(ie[5:])+5] = Exp[int(ie[5:])+5]*(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "            for iy2,y2 in enumerate(range(int(ie[:4]),int(ie[5:])+5)):\n",
    "                Exp[y2] = Eg[y2]*(DistributionFiMax[r]- \n",
    "                Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "                \n",
    "                for iy3,y3 in enumerate(reversed(range(y2,int(ie[5:])+4))):\n",
    "                    Exp[y2]+=Eg[y3+1]*(1-DistributionFiMax[r]+ \n",
    "                    Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))*\\\n",
    "                    B9[iy3+len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],iy3].values,\n",
    "                                                     (y3+1-y2)].values\n",
    "                    \n",
    "                Exp[y2] += Aggregate*B9[len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],0].values,\n",
    "                                                                         len(B9[len(dummy[0])-len(dummy[co])])-iy2].values\n",
    "                \n",
    "            Exp[int(ie[:4])] += Eg[int(ie[:4])]*(1-DistributionFiMax[r]+\n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "\n",
    "            \n",
    "        elif ie == '1994-1999' or ie == '2000-2006':\n",
    "            y = [yr for yr in range(int(ie[5:])+3,df5.columns.max())]\n",
    "\n",
    "            Exp[int(ie[5:])+3]=Eg[y].agg('sum',axis=1)\n",
    "\n",
    "            Exp.loc[:,y[1:]] = 0\n",
    "            \n",
    "            Aggregate = Exp[int(ie[5:])+3]*(1-(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r])))\n",
    "\n",
    "            Exp[int(ie[5:])+3] = Exp[int(ie[5:])+3]*(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "\n",
    "            for iy2,y2 in enumerate(range(int(ie[:4]),int(ie[5:])+3)):\n",
    "                Exp[y2] = Eg[y2]*(DistributionFiMax[r]- \n",
    "                Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "                \n",
    "                for iy3,y3 in enumerate(reversed(range(y2,int(ie[5:])+2))):\n",
    "                    Exp[y2]+=Eg[y3+1]*(1-DistributionFiMax[r]+ \n",
    "                    Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))*\\\n",
    "                    B9[iy3+len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],iy3].values,\n",
    "                                                     (y3+1-y2)].values\n",
    "                Exp[y2] += Aggregate*B9[len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],0].values,\n",
    "                                                                         len(B9[len(dummy[0])-len(dummy[co])])-iy2].values\n",
    "            \n",
    "            Exp[int(ie[:4])] += Eg[int(ie[:4])]*(1-DistributionFiMax[r]+\n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "         \n",
    "        elif ie == '2007-2013':\n",
    "            y = [yr for yr in range(int(ie[5:])+2,df5.columns.max()+1)]\n",
    "\n",
    "            Exp[int(ie[5:])+2]=Eg[y].agg('sum',axis=1)\n",
    "            Exp.loc[:,y[1:]] = 0\n",
    "            \n",
    "            Aggregate = Exp[int(ie[5:])+2]*(1-(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r])))\n",
    "\n",
    "            Exp[int(ie[5:])+2] = Exp[int(ie[5:])+2]*(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "\n",
    "            for iy2,y2 in enumerate(range(int(ie[:4]),int(ie[5:])+2)):\n",
    "                Exp[y2] = Eg[y2]*(DistributionFiMax[r]- \n",
    "                Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "                \n",
    "                for iy3,y3 in enumerate(reversed(range(y2,int(ie[5:])+1))):\n",
    "                    Exp[y2]+=Eg[y3+1]*(1-DistributionFiMax[r]+ \n",
    "                    Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))*\\\n",
    "                    B9[iy3+len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],iy3].values,\n",
    "                                                     (y3+1-y2)].values\n",
    "                Exp[y2] += Aggregate*B9[len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],0].values,\n",
    "                                                                         len(B9[len(dummy[0])-len(dummy[co])])-iy2].values\n",
    "            \n",
    "            Exp[int(ie[:4])] += Eg[int(ie[:4])]*(1-DistributionFiMax[r]+\n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "        \n",
    "        else:\n",
    "            Exp[df5.columns.max()]=Eg[df5.columns.max()]*(DistributionFiMax[r]- \n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "\n",
    "            for iy2,y2 in enumerate(reversed(range(int(ie[:4]),df5.columns.max()))):\n",
    "                Exp[y2] = Eg[y2]*(DistributionFiMax[r]- \n",
    "                Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "\n",
    "                for iy3,y3 in enumerate(reversed(range(y2,df5.columns.max()))):\n",
    "                    Exp[y2]+=Eg[y3+1]*(1-DistributionFiMax[r]+ \n",
    "                    Norm_df7.loc[pd.IndexSlice[ie,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))*\\\n",
    "                    B9[iy3+len(dummy[0])-len(dummy[co])].loc[years.loc[pd.IndexSlice[ie,:,:,:,:,r],iy3].values,\n",
    "                                                     (y3+1-y2)].values\n",
    "\n",
    "            Exp[int(ie[:4])] += Eg[int(ie[:4])]*(1-DistributionFiMax[r]+\n",
    "            Norm_df7.loc[pd.IndexSlice[ie,:,:,:,:],'$\\mu$']*(DistributionFiMax[r]-DistributionFiMin[r]))\n",
    "        \n",
    "        Expe.append(Exp)\n",
    "    Expen = pd.concat(Expe)\n",
    "    Expen['r']=r\n",
    "    Expend.append(Expen)\n",
    "Expenditure = pd.concat(Expend)\n",
    "Expenditure.set_index('r', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database originated can be finally exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expenditure.to_csv('Expenditure_including_2014-2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is eventually harmonised and merged into a single database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean = Expenditure.groupby(['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code']).mean()\n",
    "Std = Expenditure.groupby(['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_unstuck = pd.pivot_table(Mean.stack().reset_index(),values = 0,columns = 'FundingScheme',\n",
    "                                        index=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year']).reset_index()\n",
    "Std_unstuck = pd.pivot_table(Std.stack().reset_index(),values = 0,columns = 'FundingScheme',\n",
    "                                        index=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year']).reset_index()\n",
    "Payment_unstuck = pd.pivot_table(df4.stack().reset_index(),values = 0,columns = 'FundingScheme',\n",
    "                                        index=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_unstuck = Mean_unstuck.rename(columns={'ProgrammingPeriod':'Programming_Period','NUTS1Code':'NUTS1_ID','NUTS2Code':'NUTS2_ID',\n",
    "                        'ERDF_TOTAL':'ERDF','CF_TOTAL':'CF'})\n",
    "Std_unstuck = Std_unstuck.rename(columns={'ProgrammingPeriod':'Programming_Period','NUTS1Code':'NUTS1_ID','NUTS2Code':'NUTS2_ID',\n",
    "                        'ERDF_TOTAL':'ERDF','CF_TOTAL':'CF'})\n",
    "Payment_unstuck = Payment_unstuck.rename(columns={'ProgrammingPeriod':'Programming_Period','NUTS1Code':'NUTS1_ID','NUTS2Code':'NUTS2_ID',\n",
    "                        'ERDF_TOTAL':'ERDF','CF_TOTAL':'CF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_melt = pd.melt(Mean_unstuck, id_vars=['Programming_Period','Country','NUTS1_ID','NUTS2_ID','Year'], value_vars=['ERDF', 'CF',\n",
    "        'EAGGF','ESF','CF','EAFRD','EMFF','FEAD','YEI'],var_name='Fund', value_name='Modelled_annual_expenditure')\n",
    "Std_melt = pd.melt(Std_unstuck, id_vars=['Programming_Period','Country','NUTS1_ID','NUTS2_ID','Year'], value_vars=['ERDF', 'CF',\n",
    "        'EAGGF','ESF','CF','EAFRD','EMFF','FEAD','YEI'],var_name='Fund', value_name='Standard_deviation_of_annual_expenditure')\n",
    "Payments_melt = pd.melt(Payment_unstuck, id_vars=['Programming_Period','Country','NUTS1_ID','NUTS2_ID','Year'], \n",
    "        value_vars=['ERDF', 'CF','EAGGF','ESF','CF','EAFRD','EMFF','FEAD','YEI'],var_name='Fund', value_name='EU_Payment_annual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_df = pd.concat([Mean_melt,Std_melt.Standard_deviation_of_annual_expenditure],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Exp_df.join(Payments_melt.set_index(['Programming_Period','Country','NUTS1_ID','NUTS2_ID','Year','Fund']),\n",
    "            on=['Programming_Period','Country','NUTS1_ID','NUTS2_ID','Year','Fund']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUTS nomenclature is finally harmonised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output.iloc[:,-3:]=Output.iloc[:,-3:].astype(int)\n",
    "\n",
    "mapping_cat = dict(df_old[['NUTS2_ID', 'NUTS2_name']].values)\n",
    "mapping_cat['EL11']='Anatoliki Makedonia,Thraki'\n",
    "mapping_cat['EL12']='Kentriki Makedonia'\n",
    "mapping_cat['EL13']='Dytiki Makedonia'\n",
    "mapping_cat['EL14']='Thessalia'\n",
    "mapping_cat['EL21']='Ipeiros'\n",
    "mapping_cat['EL22']='Ionia Nisia'\n",
    "mapping_cat['EL23']='Dytiki Ellada'\n",
    "mapping_cat['EL24']='Sterea Ellada'\n",
    "mapping_cat['EL25']='Peloponnisos'\n",
    "mapping_cat['FRZZ']='Extra-Regio NUTS 2'\n",
    "mapping_cat['SI01']='Vzhodna Slovenija'\n",
    "mapping_cat['SI02']='Zahodna Slovenija'\n",
    "mapping_cat['UKZZ']='Extra-Regio NUTS 2'\n",
    "Output['NUTS2_name'] = Output['NUTS2_ID'].map(mapping_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formatting is set as per the instruction received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = Output[['Country','NUTS1_ID','NUTS2_ID','NUTS2_name','Fund','Year','Programming_Period','EU_Payment_annual',\n",
    "                  'Modelled_annual_expenditure','Standard_deviation_of_annual_expenditure']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>NUTS1_ID</th>\n",
       "      <th>NUTS2_ID</th>\n",
       "      <th>NUTS2_name</th>\n",
       "      <th>Fund</th>\n",
       "      <th>Year</th>\n",
       "      <th>Programming_Period</th>\n",
       "      <th>EU_Payment_annual</th>\n",
       "      <th>Modelled_annual_expenditure</th>\n",
       "      <th>Standard_deviation_of_annual_expenditure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE1</td>\n",
       "      <td>BE10</td>\n",
       "      <td>Région de Bruxelles-Capitale / Brussels Hoofds...</td>\n",
       "      <td>ERDF</td>\n",
       "      <td>1986</td>\n",
       "      <td>1989-1993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE1</td>\n",
       "      <td>BE10</td>\n",
       "      <td>Région de Bruxelles-Capitale / Brussels Hoofds...</td>\n",
       "      <td>ERDF</td>\n",
       "      <td>1987</td>\n",
       "      <td>1989-1993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE1</td>\n",
       "      <td>BE10</td>\n",
       "      <td>Région de Bruxelles-Capitale / Brussels Hoofds...</td>\n",
       "      <td>ERDF</td>\n",
       "      <td>1988</td>\n",
       "      <td>1989-1993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE1</td>\n",
       "      <td>BE10</td>\n",
       "      <td>Région de Bruxelles-Capitale / Brussels Hoofds...</td>\n",
       "      <td>ERDF</td>\n",
       "      <td>1989</td>\n",
       "      <td>1989-1993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE</td>\n",
       "      <td>BE1</td>\n",
       "      <td>BE10</td>\n",
       "      <td>Région de Bruxelles-Capitale / Brussels Hoofds...</td>\n",
       "      <td>ERDF</td>\n",
       "      <td>1990</td>\n",
       "      <td>1989-1993</td>\n",
       "      <td>0</td>\n",
       "      <td>3253</td>\n",
       "      <td>4051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362929</th>\n",
       "      <td>UK</td>\n",
       "      <td>UKZ</td>\n",
       "      <td>UKZZ</td>\n",
       "      <td>Extra-Regio NUTS 2</td>\n",
       "      <td>YEI</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362930</th>\n",
       "      <td>UK</td>\n",
       "      <td>UKZ</td>\n",
       "      <td>UKZZ</td>\n",
       "      <td>Extra-Regio NUTS 2</td>\n",
       "      <td>YEI</td>\n",
       "      <td>2015</td>\n",
       "      <td>2014-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362931</th>\n",
       "      <td>UK</td>\n",
       "      <td>UKZ</td>\n",
       "      <td>UKZZ</td>\n",
       "      <td>Extra-Regio NUTS 2</td>\n",
       "      <td>YEI</td>\n",
       "      <td>2016</td>\n",
       "      <td>2014-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362932</th>\n",
       "      <td>UK</td>\n",
       "      <td>UKZ</td>\n",
       "      <td>UKZZ</td>\n",
       "      <td>Extra-Regio NUTS 2</td>\n",
       "      <td>YEI</td>\n",
       "      <td>2017</td>\n",
       "      <td>2014-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362933</th>\n",
       "      <td>UK</td>\n",
       "      <td>UKZ</td>\n",
       "      <td>UKZZ</td>\n",
       "      <td>Extra-Regio NUTS 2</td>\n",
       "      <td>YEI</td>\n",
       "      <td>2018</td>\n",
       "      <td>2014-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322608 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country NUTS1_ID NUTS2_ID  \\\n",
       "0           BE      BE1     BE10   \n",
       "1           BE      BE1     BE10   \n",
       "2           BE      BE1     BE10   \n",
       "3           BE      BE1     BE10   \n",
       "4           BE      BE1     BE10   \n",
       "...        ...      ...      ...   \n",
       "362929      UK      UKZ     UKZZ   \n",
       "362930      UK      UKZ     UKZZ   \n",
       "362931      UK      UKZ     UKZZ   \n",
       "362932      UK      UKZ     UKZZ   \n",
       "362933      UK      UKZ     UKZZ   \n",
       "\n",
       "                                               NUTS2_name  Fund  Year  \\\n",
       "0       Région de Bruxelles-Capitale / Brussels Hoofds...  ERDF  1986   \n",
       "1       Région de Bruxelles-Capitale / Brussels Hoofds...  ERDF  1987   \n",
       "2       Région de Bruxelles-Capitale / Brussels Hoofds...  ERDF  1988   \n",
       "3       Région de Bruxelles-Capitale / Brussels Hoofds...  ERDF  1989   \n",
       "4       Région de Bruxelles-Capitale / Brussels Hoofds...  ERDF  1990   \n",
       "...                                                   ...   ...   ...   \n",
       "362929                                 Extra-Regio NUTS 2   YEI  2014   \n",
       "362930                                 Extra-Regio NUTS 2   YEI  2015   \n",
       "362931                                 Extra-Regio NUTS 2   YEI  2016   \n",
       "362932                                 Extra-Regio NUTS 2   YEI  2017   \n",
       "362933                                 Extra-Regio NUTS 2   YEI  2018   \n",
       "\n",
       "       Programming_Period  EU_Payment_annual  Modelled_annual_expenditure  \\\n",
       "0               1989-1993                  0                            0   \n",
       "1               1989-1993                  0                            0   \n",
       "2               1989-1993                  0                            0   \n",
       "3               1989-1993                  0                            0   \n",
       "4               1989-1993                  0                         3253   \n",
       "...                   ...                ...                          ...   \n",
       "362929          2014-2020                  0                            0   \n",
       "362930          2014-2020                  0                            0   \n",
       "362931          2014-2020                  0                            0   \n",
       "362932          2014-2020                  0                            0   \n",
       "362933          2014-2020                  0                            0   \n",
       "\n",
       "        Standard_deviation_of_annual_expenditure  \n",
       "0                                              0  \n",
       "1                                              0  \n",
       "2                                              0  \n",
       "3                                              0  \n",
       "4                                           4051  \n",
       "...                                          ...  \n",
       "362929                                         0  \n",
       "362930                                         0  \n",
       "362931                                         0  \n",
       "362932                                         0  \n",
       "362933                                         0  \n",
       "\n",
       "[322608 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the relevant statistical properties of the distributions calculated (mean and standard deviation) can be also calculated and exported in a datasheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output.to_excel('PivotedData_including_2014-2020.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
