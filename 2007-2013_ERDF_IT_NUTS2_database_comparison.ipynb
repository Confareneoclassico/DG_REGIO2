{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sobol_seq\n",
    "from tabulate import tabulate\n",
    "import types\n",
    "\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            \n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "            \n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to uniform the database formatting as to ease their cross-comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(x):\n",
    "    return pd.pivot_table(pd.melt(x,id_vars=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year'],\n",
    "        var_name='FundingScheme'),index=['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code'],\n",
    "        values='value',columns='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the dataset and isolate the rows relative to DG REGIO programmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('20181231 Pagamenti ammessi PO 2007-2013.xls',usecols=[0,1,2,3,4,5,7])\n",
    "df_EU = pd.read_excel('Database_Final_UPD(3).xlsx')\n",
    "df_REGIO = df[(df['CCI'].str.contains(\"161\"))|df['CCI'].str.contains(\"162\")]\n",
    "df_expenditures = pd.read_excel('PivotedData.xlsx',sheet_name='Mean',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let harmonise the nomenclature across databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS2_dic = {'ABRUZZO':'ITF1','BASILICATA':'ITF5','CALABRIA':'ITF6','CAMPANIA':'ITF3','EMILIA':'ITH5','FRIULI':'ITH4','LAZIO':'ITI4',\n",
    "'LIGURIA':'ITC3','LOMBARDIA':'ITC4','MARCHE':'ITI3','MOLISE':'ITF2','PIEMONTE':'ITC1','PUGLIA':'ITF4','SARDEGNA':'ITG2','SICILIA':'ITG1',\n",
    "'TOSCANA':'ITI1','TRENTINO':'ITH0','UMBRIA':'ITI2',\"VALLE D'AOSTA\":'ITC2','VENETO':'ITH3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us normalise the database as to make figures consistent between the Italian and the EU datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_capped = df_REGIO[df_REGIO.ANNO<2017]\n",
    "\n",
    "df_REGIO_capped['NUTS2'] = df_REGIO_capped.REGIONE.map(NUTS2_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let adjust the database formatting for the sake of comparability across figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = [df_EU,df_expenditures]\n",
    "ds_names = ['EU_Payments','Expenditures']\n",
    "ds_pivoted = dict(zip(ds_names,[formatting(ds) for ds in DS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us re-attribute the items unclearly allocated to the different regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_nonAttributed = df_REGIO_capped[(df_REGIO_capped.REGIONE=='STATO ESTERO')|(df_REGIO_capped.REGIONE=='PLURI')|(df_REGIO_capped.REGIONE=='AMBITO NAZIONALE')]\n",
    "df_REGIO_nonAttributed_yearly = df_REGIO_nonAttributed.groupby('ANNO').sum()\n",
    "df_REGIO_nonAttributed_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_REGIO = df_REGIO_capped[(df_REGIO_capped.REGIONE!='STATO ESTERO')&(df_REGIO_capped.REGIONE!='PLURI')&\n",
    "                                 (df_REGIO_capped.REGIONE!='AMBITO NAZIONALE')]\n",
    "df_REGIO_REGIO['NUTS2'] = df_REGIO_REGIO.REGIONE.map(NUTS2_dic)\n",
    "df_REGIO_REGIO['multiplier']= df_REGIO_REGIO.NUTS2.map((df_REGIO_REGIO.groupby('NUTS2').sum()/\n",
    "                                                        df_REGIO_REGIO.groupby('NUTS2').sum().sum()).PAGAMENTO_AMMESSO_UE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_REGIO_yearly = df_REGIO_REGIO.groupby(['NUTS2','ANNO','multiplier']).sum()\n",
    "df_REGIO_REGIO_yearly.PAGAMENTO_AMMESSO_UE=df_REGIO_REGIO_yearly.PAGAMENTO_AMMESSO_UE+df_REGIO_REGIO_yearly.index.get_level_values(2)*\\\n",
    "df_REGIO_REGIO_yearly.index.get_level_values(1).map(df_REGIO_nonAttributed_yearly.PAGAMENTO_AMMESSO_UE)\n",
    "df_REGIO_REGIO_yearly=df_REGIO_REGIO_yearly.droplevel(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let isolate the IT figures for the programming period 2007-2013, the funding scheme ERDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ERDF_20172013_IT=ds_pivoted['Expenditures'].loc['2007-2013','ERDF_TOTAL','IT',:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines need to be run twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ERDF_20172013_IT.loc[('2007-2013','ERDF_TOTAL','IT','ITH','ITH0'),:] = \\\n",
    "df_ERDF_20172013_IT.loc[pd.IndexSlice[:,:,:,:,'ITH1'],:].droplevel(4).values+\\\n",
    "df_ERDF_20172013_IT.loc[pd.IndexSlice[:,:,:,:,'ITH2'],:].droplevel(4).values \n",
    "\n",
    "df_ERDF_20172013_IT = df_ERDF_20172013_IT.drop('ITH1',level='NUTS2Code').drop('ITH2',level='NUTS2Code').sort_index(by='NUTS2Code')\n",
    "\n",
    "Excess=(df_REGIO_REGIO_yearly.groupby('NUTS2').sum()).PAGAMENTO_AMMESSO_UE-df_ERDF_20172013_IT.groupby('NUTS2Code').sum().sum(axis=1)\n",
    "\n",
    "Excess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us test how the assumption on the number of years from which the exceeding payment should be cut out for the sake of normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_REGIO_yearly['Year']=df_REGIO_REGIO_yearly.index.get_level_values(1)\n",
    "df_REGIO_REGIO_yearly=df_REGIO_REGIO_yearly.droplevel(1)\n",
    "df_REGIO_pv = df_REGIO_REGIO_yearly.pivot_table(index='Year', columns='NUTS2', values='PAGAMENTO_AMMESSO_UE').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_l = []\n",
    "distance_y = []\n",
    "norm = []\n",
    "idx = []\n",
    "for ei,i in enumerate(reversed(df_REGIO_pv.index)):\n",
    "    df_REGIO_norm = df_REGIO_pv.copy()\n",
    "    df_REGIO_norm.loc[i:2016]=df_REGIO_pv.loc[i:2016]-Excess/(2016-i+1)\n",
    "    norm.append(df_REGIO_norm)\n",
    "    distance_l.append((np.abs((df_REGIO_norm.cumsum()-df_ERDF_20172013_IT.droplevel([0,1,2,3]).T.loc[2007:].cumsum())/\\\n",
    "                       df_REGIO_norm.sum())).sum().round(1))\n",
    "    distance_y.append(np.abs(df_REGIO_norm.cumsum()-df_ERDF_20172013_IT.droplevel([0,1,2,3]).T.loc[2007:].cumsum()))\n",
    "    distance_y[-1]['years']=ei+1\n",
    "    norm[-1]['years']=ei+1\n",
    "distance = pd.concat(distance_l,axis=1).T\n",
    "distance.index = distance.index+1\n",
    "distance_yearly = pd.concat(distance_y).sort_index()\n",
    "norm_df = pd.concat(norm).sort_index()\n",
    "\n",
    "distance_yearly.set_index('years',append=True, inplace=True)\n",
    "norm_df.set_index('years',append=True, inplace=True)\n",
    "\n",
    "distance_yearly=distance_yearly.swaplevel().sort_index(by=['years','Year'])\n",
    "norm_df=norm_df.swaplevel().sort_index(by=['years','Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the min-max range for the normalised figures for the sake of comparison again the individual NUTS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: by argument to sort_index is deprecated, please use .sort_values(by=...)\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: by argument to sort_index is deprecated, please use .sort_values(by=...)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "norm_data = norm_df.groupby('Year').min()\n",
    "norm_data['val']='min'\n",
    "norm_data.set_index('val',append=True, inplace=True)\n",
    "norm_data=norm_data.swaplevel().sort_index(by=['val','Year'])\n",
    "norm_data2 = norm_df.groupby('Year').max()\n",
    "norm_data2['val']='max'\n",
    "norm_data2.set_index('val',append=True, inplace=True)\n",
    "norm_data2=norm_data2.swaplevel().sort_index(by=['val','Year'])\n",
    "norm_dataset = pd.concat([norm_data,norm_data2]).to_csv('norm_IT_NUTS2.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.concat([norm_df.loc[pd.IndexSlice[:,yr],:].min() for yr in range(2007,2017)]),\n",
    "           pd.concat([norm_df.loc[pd.IndexSlice[:,yr],:].max() for yr in range(2007,2017)])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pd.read_csv('mu_IT.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mu.rank(ascending=False),distance.max().rank(),label=distance.max().index)\n",
    "plt.xlabel('index of regional specificity reverse rank')\n",
    "plt.ylabel('maximum distance rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mu.rank(ascending=False),distance.min().rank(),label=distance.max().index)\n",
    "plt.xlabel('index of regional specificity reverse rank')\n",
    "plt.ylabel('minimum distance rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
