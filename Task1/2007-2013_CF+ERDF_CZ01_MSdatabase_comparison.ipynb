{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sobol_seq\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            \n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "            \n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to uniform the database formatting as to ease their cross-comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(x):\n",
    "    return pd.pivot_table(pd.melt(x,id_vars=['ProgrammingPeriod','Country','NUTS1Code','NUTS2Code','Year'],\n",
    "        var_name='FundingScheme'),index=['ProgrammingPeriod','FundingScheme','Country','NUTS1Code','NUTS2Code'],\n",
    "        values='value',columns='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the dataset and isolate the rows relative to DG REGIO programmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('nuts_prog_kat_Cohesion_codesonly_v3.xlsx',usecols=[0,1,5,6,9,10,11,12])\n",
    "\n",
    "df_EU = pd.read_excel('Database_Final_UPD(3).xlsx')\n",
    "df_REGIO = df[(df['CCI'].str.contains(\"161\"))|df['CCI'].str.contains(\"162\")]\n",
    "df_expenditures = pd.read_excel('PivotedData.xlsx',sheet_name='Mean',index_col=0)\n",
    "\n",
    "df_REGIO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us normalise the database as to make figures consistent between the Czech and the EU datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_capped = df_REGIO[df_REGIO.year<2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption on the exchange rate - retrieved from http://sdw.ecb.europa.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ER = pd.read_csv('CZK_EURO_historical_exchange_rate.csv')\n",
    "ExchangeRates = ER.copy()\n",
    "ExchangeRates['year']=ER.date.astype(str).str[:4].astype(int)\n",
    "ExchangeRates = ExchangeRates[(ExchangeRates['year']>2006)&(ExchangeRates['year']<2017)]\n",
    "ExchangeRates=ExchangeRates.drop(['date','conf'],axis=1).set_index('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let adjust the database formatting for the sake of comparability across figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = [df_EU,df_expenditures]\n",
    "ds_names = ['EU_Payments','Expenditures']\n",
    "ds_pivoted = dict(zip(ds_names,[formatting(ds) for ds in DS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let isolate the IT figures for the programming period 2007-2013, the funding scheme ERDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ERDF = ds_pivoted['Expenditures'].loc['2007-2013','ERDF_TOTAL','CZ',:,:]\n",
    "ds_ERDF.index = ds_ERDF.index.droplevel(1)\n",
    "ds_CF = ds_pivoted['Expenditures'].loc['2007-2013','CF_TOTAL','CZ',:,:]\n",
    "ds_CF.index = ds_CF.index.droplevel(1)\n",
    "df_20072013_CFERDF_CZ=(ds_ERDF+ds_CF).T.loc[2007:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_REGIO_yearly = df_REGIO_capped.groupby('year')\n",
    "df_REGIO_su = pd.DataFrame([dfr['EU (czk)'].sum() for idf, dfr in df_REGIO_yearly], \n",
    "                            index=[idf for idf, dfr in df_REGIO_yearly],columns=['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = [ExchangeRates.mean(),ExchangeRates]\n",
    "er_n = ['Constant','Yearly average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us test how the assumption on the number of years from which the exceeding payment should be cut out for the sake of normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cumulative distance is 0.4\n",
      "The cumulative distance is 0.4\n",
      "The cumulative distance is 0.37\n",
      "The cumulative distance is 0.37\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(df_REGIO_su.index[::9]):\n",
    "    plt.step(df_REGIO_su.index,df_20072013_CFERDF_CZ.T.loc[2007:].T.sum().expanding(1).sum(),label='Estimated Expenditure')\n",
    "    for ie,er in enumerate(exchange_rate):\n",
    "        df_REGIO_sum = df_REGIO_su/er.values\n",
    "        Excess = -df_20072013_CFERDF_CZ.sum().sum()+df_REGIO_sum.sum()\n",
    "        df_REGIO_norm = df_REGIO_sum.copy()\n",
    "        df_REGIO_norm.loc[i:2016]=df_REGIO_sum.loc[i:2016]-Excess/(2016-i+1)\n",
    "        print('The cumulative distance is ' + str((abs(df_REGIO_norm.values[:,0]-df_20072013_CFERDF_CZ.T.loc[2007:].T.sum().values).sum()/\n",
    "              df_REGIO_norm.values[:,0].sum()).round(2)))\n",
    "        plt.step(df_REGIO_sum.index,df_REGIO_norm.expanding(1).sum(),label='CZ database '+er_n[ie]+\n",
    "                 ' exchange rate')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Amount, â‚¬')\n",
    "    plt.title('Normalised over '+str(int(2016-i+1))+' year(s), '+str(i)+'-2016')\n",
    "    plt.legend()\n",
    "    plt.savefig(time.strftime(\"%Y.%m.%d\") + '_2007-2013_CF-ERDF_CZ expenditure database ' + \n",
    "                'Normalised over '+str(int(2016-i+1))+' year(s), '+str(i)+'-2016'+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
